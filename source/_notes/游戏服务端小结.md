---
title: 游戏服务端小结
date: 2021-10-24 12:58:26
tags: 
---

摘要：此处简要整理一下，工作中的收获
[网络同步和网络架构](https://mp.weixin.qq.com/s/8YsMcKFKPRFrmiPMlsyKZg)

<!--more -->

* 游戏服务端与互联网服务端的区别?
* 为什么使用udp?
* 网络模块的基础：1. 网络通信，使用tcp或kcp等可靠的协议实现可靠的通信模块。2. 序列化与反序列化，保证服务端与客户端的数据可以通过网络通道进行可靠的数据传输。
* 双端通信的协议：客户端与服务端互相理解双方数据的方法，个人觉得，在此基础上的都是应用层的协议了，例如http协议，rpc过程调用，甚至包括自己随心所欲实现的通信方式。
* 虚拟机容器的作用：1. 使得服务端运行的环境变得可以随身携带，轻易部署。2. 使得单机可以部署许多服务，提高了硬件的使用效率。
* linux环境需要比较熟悉，各种命令和原理都应理解，如：权限，文本分析，环境变量，网络模块，shell脚本，存储，进程线程，其中通信模块应当深入学习。
* 分布式架构相关知识：保证服务器的可靠性，可扩展性，容灾能力，安全性等。目前见到的方式都挺朴素的。
* 存储相关：cap理论，sql与nosql，主从同步，索引，mongodb，redis数据结构，事务。
* 微服务与游戏服区别和使用场景，微服务的服务注册发现，负载均衡，服务降级和熔断，服务部署，反向代理等

***
* 游戏的账号系统，顶号流程和断线重连流程。
* 多服和跨服结构下的流程，玩家数据存档方式，服务器划分，服务器切换流程，数据迁移方式。
* 协程框架。
* 游戏内网络同步框架。


@2022/4/21
准备润了，回顾和整理一下

s2多人联机战斗分享
1. 介绍了graph的设计，这部分是离表现最近的，**核心是为了控制姿态和位移的并行计算**，项目分为了5层graph，从底往上分别为：
    环境感知（例如检查梯子，抛出事件供脚本处理），MotionInfo（输出位移，如引力场，寻路），LocoMotion（基础移动，和姿态开始相关，例如走跑等，同时也会输出位移），Action（互斥姿态控制层，技能、受击、死亡动画之类），弱表现控制层（例如弱受击，叠加姿态到整体）
    用于先行做表现也比较方便
2. 技能系统，使用timeline编辑，加上各种逻辑业务实现相关需求
3. 使用状态机进行rpc一致性同步，里面涉及的一个问题就是上行下行控制消息可能会有冲突，需要逐个确认或者回退
4. 使用高级指令进行战斗同步，这个主要解决的是，弱网络下，使用影子跟随可能拉扯会比较严重。这个方案是服务端客户端各自根据这个指令进行控制和表现，对于结果不一致和误差，会进行修复使得结果近似。（找合适的时机悄悄修正，例如浮空）
5. 战斗结算，单人pve，多人pve，pvp；分别采用不同的碰撞检测和结算方法，越往后越严

***
### mongodb
* 反范式化可以减少额外查询次数，但可能导致数据不一致，对于更新频率很低的数据，可以采用此种方式。
* 对文档大小修改会很费性能，最好不要频繁新加数据，可以预先分配好空间，用垃圾数据填充一下
* 尽量不要让mongodb跑脚本做计算任务，性能很低，最好存进去的时候直接已经算好，或者拿再做额外计算
* 复合索引可以被多个查询（部分）使用，甚至可以直接覆盖一些简单的查询。
* 执行命令的本质也是一个查询，并且命令也是一种集合`$cmd`

### 网络编程教程（陈硕）
* NTP协议，用来校准时钟，方法：`((T1 + T4) - (T2 + T3)) / 2`，其中`T1`表示客户端发送请求的时间，`T2`表示服务端接收到请求的时间，`T3`表示服务端响应的时间，`T4`表示客户端收到响应的时间。求出的结果即为客户端与服务端的时间差，校准时应当缓慢的校准，不宜突变，否则会产生震荡，校准的是**频率**，这样子才能保证越来越准。[算法](https://www.eecis.udel.edu/~mills/precision.html)
* 他在本机上测试了一波，大致结论是，本机与本机的时钟差异大概几微秒，但是请求的一个来回时间比较大，大概有0.x毫秒（**本机网络协议栈一个来回花费的时间大约0.1毫秒**），在没有运行NTP的情况下，两台机器的时间差距大概有3毫秒。如果对延迟比较敏感，最好采用同进程里信号量交换的方式，以太网的延迟还挺高。
* 他在第16讲详细讲了UTC时间和UnxiTime的区别，指出了瑞秒（由于地球变慢修正的时间）带来的两个问题：1. 股票交易时时间可能会跳。2. 各种代码难以处理时间为负的情况，且难以测试，易导致那个时刻出现大bug。有一个解决方法，是使用三角函数`cos`来模拟时间，保证时间连续且导数频率也连续。

15. udp/tcp
    udp: nat穿透，不在乎可靠性时，没有流量控制无法有效利用带宽，支持多线程并发，数据包协议自动会获取报文边界
    tcp: 线程不安全，不能使用多线程读写

17. `netcat`比较高级的命令，测试网络带宽
    `nc < /dev/zero`, `nc > /dev/null`, `dd /dev/zero | nc`, `nc < file, nc > file`
17. 如果些程序发完数据直接关闭socket，会使用RST关闭连接，会导致缓冲区的数据可能未被发完，从而客户端无法接收到完整的数据；安全的做法，服务端关闭写操作`stream->shtudownWrite()`，并且一直读数据，直到返回0`(stream->receiveSome(buf, sizeof buf) > 0)`表示遇到了EOF，此时关闭socket是安全的
    1. correct sender: send() + shutdown(WR) + read()->0 + close()
    2. correct receiver: read()->0 + if nothing more to send + close()
    3. 只有当对面的连接关闭`close`时，`read`才会返回0。可以添加超时保证安全；可以添加长度使服务端可以知晓结束。

18. `SIGPIPE`如果向一个已经关闭的连接写数据会收到该信号。会导致服务端crash，可以初始化时设置忽略，但是要自己手动处理被关闭的情况。
18. `Nagle's algorithm, TPC_NODELAY`如果已经发了数据，在未收到响应之前发数据，会等到收到响应ACK了才发送，会导致下次发送的数据延迟一个RTT。（对于并发情况，应用层很难做合并，导致延迟大大增加）推荐关闭该选项。
    ```shell
    # 使用tcpdump可以看到消息来往的情况
    sudo tcpdump -i eth3 -n tcp port 3210
    ```
18. `SO_REUSEADDR`选项，可以让tcp服务器在crash时立即重启，或者监听后使用fork来处理请求的情况（防止不能在原来的端口监听）

21. io复用一般和非阻塞io一起使用。如果使用阻塞io，那么如果阻塞了整个io的事件都会被挡住
21. select使用事件循环，要使用非阻塞io来处理，检查是否可读不能解决阻塞问题，会有以下两种情况：
    1. 当有新的连接显示可读时，如果尝试调用`accept`，可能客户端已经断开连接导致阻塞。
    2. linux可能有bug，有可能会告诉会阻塞的描述符为可读状态。
21. select, poll, epoll（还要多看看）
    边缘触发：适用于发送数据和接收连接，用事件来触发。 一次性的，触发了但数据没处理完不会再触发。
    水平触发：使用于接收数据（没有新数据到来不会通知可读。

22. 使用非阻塞IO
* 非阻塞io难点：
    1. 需要处理short read和short write
    2. 应用层需要有对应的缓冲区
    3. 使用非阻塞的网络库
* 使用阻塞io，1. 在accept时可能客户已断开连接，此时会阻塞下去。2. select有可能会意外报告可读

* 在非阻塞io下，
    收消息的注意点：网络库需要接收完整的消息后，再触发上层的具体逻辑
    发消息的注意点： 1. 如果发送缓冲区为空，可直接向网络描述符上写数据，否则添加至缓冲区的尾部。 2. 发送数据若发生short write，那么需要监听`POLLOUT`文件描述符可写事件，并且需要发送的数据都逐个添加到缓冲区。 3. 事件触发后，从缓冲区中拿取数据往文件描述符写，直到缓冲区为空，取消监听`POLLOUT`事件（若未取消且为水平触发，会导致cpu空转）。
* 边缘触发和水平触发，前者只通知一次事件需一次性全部处理完，后者会一直通知直到处理完毕

33. 网络io模型
    * linux下都是同步io，分为阻塞和非阻塞，异步io模型除非使用`async`相关模块
    * 如果用阻塞io，那么文件描述符的读写应当放到线程中执行（例如使用线程池），但是不能将epoll所在的线程阻塞，而是监听到对应的事件后，交由不同的线程处理。

39. 并发模型
    1. 单线程事件循环模型
        不能使用到多核，每个连接的请求都是顺序执行（可起多个进程配合负载均衡实现）
    2. 单线程事件循环IO + 线程池计算模型 （线程池会并行处理多个请求，可以有效的利用cpu多核）
    3. 多线程事件循环模型（请求可能落到不同的线程，会导致计算资源分配不公）
    4. 多线程处理事件循环 + 线程池做计算
    可能问题：1. 线程池计算速度无法快速消耗io线程，导致堆积内存过载；2. io写数据堆积

45. 过载保护; 线程池的处理速度低于io线程处理请求的速度：
    1. 当任务队列数大于一定程度，worker线程池会直接拒绝请求；
    2. 发送缓冲区会维护是否高水位状态，超出阈值就直接关闭连接拒绝请求。

46. 负载均衡
    1. 客户端库进行选择，反向代理，旁路代理
    2. 连接级：不管协议直接根据连接数目分配；请求级：会管一下后面服务的负载

47. 产品级
    1. 心跳（可方便服务器进行维护） 
    2. 监控 
    3. 硬件资源估计

48. Hub Server
    消息订阅和发布，需要注意防止

49. TCP Relay tcp中继 
    就是创建一个服务，进行数据端口转发
    需要注意的问题：1. 考虑双方带宽可能不匹配，如果是非阻塞的读，会不断接收接收导致缓冲区撑爆；2. 可使用高低水位来接收的容量，超过高水位就不再读取，可以达到流量控制的目的

58. TCP半连接
    tcp半关连接：只发送不接收，或者只接受不发送；出现情况为：
        客户端调用了`shutdown(send)`并未调用`close`，此时客户端仍然可以接受更多的数据
        服务端在`read`返回0后并不能判断连接是否关闭，通常来说，也不能直接关闭调用`close`
    ![tcp状态图](/images/tcp%E7%8A%B6%E6%80%81%E5%9B%BE.png): 
    1. 当客户端调用`shutdown(send)`时会发送`FIN`标志，客户端进入`FIN_WAIT_1`状态，收到了服务端的`ACK`后会进入`FIN_WAIT_2`状态，此时的客户端仍然时可以接收数据，直到收到可服务端的`FIN`之后，会进入`TIME_WAIT`状态，`2msl`后进入`CLOSED`状态。
    2. 当服务端收到`FIN`后，该连接会进入`CLOSE_WAIT`状态，这段时间内依旧可以向客户端发送数据，此时就称为**半连接**的状态，发送完数据后再发送`FIN`即可关闭该条连接，进入`CLOSED`状态

61. 视频里讲解了一个竞态条件的发生：
    主要问题是注册低水位回调是放到了一个事件队列里（延迟回调，防止重入），但是尚未注册进去时，数据已经发送且满足了回调的条件，导致无法触发到回调
    解决方法：在回调触发的地方检查是否有需要发送的数据，没有可以接着读

62. SOCKS4 / SOCKS4a
    SOCKS4  指定ip地址，转发指定ip的数据包
    SOCKS4a 可以指定hostName，服务器会帮助进行地址解析（DNS解析是会阻塞的，应该使用异步接口）

65. 多线程和事件驱动取舍
    [觉得线程不行](https://blog.acolyer.org/2014/12/09/why-threads-are-a-bad-idea/)
    [觉得事件不行](https://blog.acolyer.org/2014/12/10/why-events-are-a-bad-idea/)
    我扫了一眼，说线程不行是因为：不太好用，需要用锁，表现一般；说事件不行是因为：线程可以同步执行逻辑清晰，异步流程也不太好用，现实中有很多独立的并发请求，用线程比较好维护
    作者的想法是：能用线程就用，不行再用事件

66. NAT来做端口转发，在应用层实现协议栈中的内容

67. tcp的可靠性
    当调用`send(sockfd, "hello", 5)`返回5时，只是表明数据写入了本机操作系统的发送缓冲区，并不是已经到达了对面。
    就算收到了`ACK`，只能表明数据已经写入了对方的接收缓冲区，但是实际对方有没有调用`read`去读取数据时不可知的。也有可能进程已经阻塞挂起了等情况，最好在消息中加入检验，以真正实现可靠。